{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9149717a-b1c4-45c7-96aa-f946dbb7e2bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy: 1.23.5\n",
      "Torch: 1.13.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    accuracy_score,\n",
    "    f1_score\n",
    ")\n",
    "import torch\n",
    "from torch.nn import (\n",
    "    Sequential,\n",
    "    Linear,\n",
    "    ReLU,\n",
    "    Softmax,\n",
    "    Sigmoid,\n",
    "    CrossEntropyLoss,\n",
    "    MSELoss,\n",
    "    Conv2d,\n",
    "    MaxPool2d,\n",
    "    Flatten,\n",
    "    ConvTranspose2d,\n",
    "    Unflatten,\n",
    "    LayerNorm,\n",
    "    BCELoss\n",
    ")\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision.io import read_image\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from torchvision.transforms import Compose\n",
    "from tqdm.auto import trange, tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"NumPy:\", np.__version__)\n",
    "print(\"Torch:\", torch.__version__)\n",
    "\n",
    "seed = 123\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11b3ef02-de37-4b37-89d4-687fd02fe870",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def gen_image_array(folder_path, stepSize, windowSize, split=[0.6,0.8]):\n",
    "#     img_arr = []\n",
    "#     i=0\n",
    "#     for file in tqdm(os.listdir(folder_path)):\n",
    "#         image_path = os.path.join(folder_path, file)\n",
    "#         image = read_image(image_path)\n",
    "#         for y in range(0, image.shape[1]-windowSize[0], stepSize):\n",
    "#             for x in range(0, image.shape[2]-windowSize[1], stepSize):\n",
    "#                 img_arr.append(image[:,y:y+windowSize[0],x:x+windowSize[1]])\n",
    "#                 i+=1\n",
    "#                 if i%1000 == 0:\n",
    "#                     torch.save(torch.stack(img_arr),f\"Img_uint/image_array_{i}.pt\")\n",
    "#                     img_arr = []\n",
    "#     torch.save(torch.stack(img_arr),f\"Img_uint/image_array_{i}.pt\")\n",
    "#     return i#, bbox_arr, windowSize\n",
    "\n",
    "# gen_image_array(\"Astro_img/\", 200, (200, 200))\n",
    "\n",
    "image_array = []\n",
    "for file in os.listdir(\"Img_uint/\"):\n",
    "    image_array.extend(torch.load(os.path.join(\"Img_uint/\",file)))\n",
    "\n",
    "image_array = torch.stack(image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe3b5758-e340-4604-8751-379a212c6934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric(\n",
    "    array,\n",
    "    label=[\"train_loss\", \"val_loss\", \"train_acc\", \"val_acc\"],\n",
    "    log=True\n",
    "):\n",
    "    for array, label in zip(array, label):\n",
    "        plt.plot(array, label=label)\n",
    "    plt.legend()\n",
    "    plt.ticklabel_format(axis=\"both\",\n",
    "                         style=\"sci\",\n",
    "                         scilimits=(0, 0),\n",
    "                         useMathText=True)\n",
    "    plt.title(\"Loss vs Epochs\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    if log:\n",
    "        plt.ylabel(\"log_loss\")\n",
    "        plt.yscale(\"log\")\n",
    "    else:\n",
    "        plt.ylabel(\"loss\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def train_model(model, epochs, loss_fn, optim, train_loader, val_loader):\n",
    "    train_loss = np.array([])\n",
    "    val_loss = np.array([])\n",
    "    # train_acc = []\n",
    "    # val_acc = []\n",
    "    pbar = trange(epochs, desc=\"Epoch\", unit=\" epoch\", position=1)\n",
    "\n",
    "    for epoch in pbar:\n",
    "        train_batch_loss = []\n",
    "        val_batch_loss = []\n",
    "        # train_batch_acc = []\n",
    "        # val_batch_acc = []\n",
    "\n",
    "        model.train()\n",
    "        pbar2 = tqdm(train_loader, desc=\"Batch\", position=1, leave=False)\n",
    "        for X_batch, y_batch in pbar2:\n",
    "            y_pred = model(X_batch.to(device))\n",
    "            loss = loss_fn(y_pred, y_batch.to(device))\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            train_batch_loss.append(loss.item())\n",
    "            # train_batch_acc.append(\n",
    "            #     np.mean(\n",
    "            #         (y_pred.argmax(axis=1) == y_batch.argmax(axis=1))\n",
    "            #         .cpu().detach().numpy()).item()\n",
    "            # )\n",
    "            pbar2.set_description(f\"Train Loss {loss.item():.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            pbar3 = tqdm(val_loader, desc=\"Batch\", position=2, leave=False)\n",
    "            for X_batch, y_batch in pbar3:\n",
    "                y_pred = model(X_batch.to(device))\n",
    "                loss = loss_fn(y_pred, y_batch.to(device))\n",
    "                val_batch_loss.append(loss.item())\n",
    "                # val_batch_acc.append(\n",
    "                #     np.mean(\n",
    "                #         (y_pred.argmax(axis=1) == y_batch.argmax(axis=1))\n",
    "                #         .cpu().detach().numpy()).item()\n",
    "                # )\n",
    "                pbar3.set_description(f\"Val Loss {loss.item():.4f}\")\n",
    "\n",
    "            mean_train_batch_loss = np.mean(train_batch_loss)\n",
    "            mean_val_batch_loss = np.mean(val_batch_loss)\n",
    "            # mean_train_batch_acc = np.mean(train_batch_acc)\n",
    "            # mean_val_batch_acc = np.mean(val_batch_acc)\n",
    "\n",
    "            train_loss=np.concatenate((train_loss,np.asarray(train_batch_loss)))\n",
    "            val_loss=np.concatenate((val_loss,np.asarray(val_batch_loss)))\n",
    "            # train_acc.append(mean_train_batch_acc)\n",
    "            # val_acc.append(mean_val_batch_acc)\n",
    "            pbar.set_description(f\"Epoch Loss [train: {mean_train_batch_loss:.4f},\\\n",
    "            val: {mean_val_batch_loss:.4f}]\")\n",
    "\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def pred_model(model, test_loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = []\n",
    "        y_test = []\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            y_pred_batch = model(X_batch.to(device))\n",
    "            y_pred.extend(y_pred_batch)\n",
    "            y_test.extend(y_batch)\n",
    "    return torch.stack(y_pred).cpu(), torch.stack(y_test).cpu()\n",
    "\n",
    "def show(imgs):\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.detach()\n",
    "        img = to_pil_image(img)\n",
    "        axs[0, i].imshow(np.asarray(img))\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "\n",
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=1.):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f555a888-5554-4647-aaa1-974511697731",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomImageDataset_v2(Dataset):\n",
    "    def __init__(self, images, transform=None, target_transform=None):\n",
    "        self.images = images\n",
    "        self.length = images.shape[0]\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]/255\n",
    "        x = self.transform(image) if self.transform else image\n",
    "        y = self.target_transform(image) if self.target_transform else image\n",
    "        \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86f5a982-20d2-4e78-ac08-278a2574e9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Astrodataset = CustomImageDataset_v2(\n",
    "    image_array,\n",
    "    transform=AddGaussianNoise(std=0.1, mean=0.0)\n",
    ")\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(Astrodataset,[0.6,0.2,0.2])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "611b216b-cf7e-4a5f-9714-8e01e420c2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "latend_dim = 64\n",
    "Autoencoder = Sequential(\n",
    "    Conv2d(3, 8, 3, stride=2, padding=1),\n",
    "    ReLU(),\n",
    "    Conv2d(8, 16, 3, stride=2, padding=1),\n",
    "    ReLU(),\n",
    "    Flatten(),\n",
    "    Linear(16*50*50,128),\n",
    "    ReLU(),\n",
    "    Linear(128, latend_dim),\n",
    "    ReLU(),\n",
    "    Linear(latend_dim,128),\n",
    "    ReLU(),\n",
    "    Linear(128,16*50*50),\n",
    "    ReLU(),\n",
    "    Unflatten(1,(16,50,50)),\n",
    "    ReLU(),\n",
    "    ConvTranspose2d(16, 8, 3, stride=2, padding=1, output_padding=1),\n",
    "    ReLU(),\n",
    "    ConvTranspose2d(8, 3, 3, stride=2, padding=1, output_padding=1),\n",
    "    Sigmoid()\n",
    ").to(device)\n",
    "loss_fn = BCELoss()\n",
    "optim = Adam(params=Autoencoder.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c790b7d-89fb-478d-bf6a-9bad4b67851d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d89a6973d0a4040bb0d120c4704ddfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/2 [00:00<?, ? epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/336 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/336 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = train_model(\n",
    "    Autoencoder, \n",
    "    epochs=2, \n",
    "    loss_fn=loss_fn,\n",
    "    optim=optim, \n",
    "    train_loader=train_loader, \n",
    "    val_loader=val_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3a12a9-9c29-4725-b14d-f28c19bb1623",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
